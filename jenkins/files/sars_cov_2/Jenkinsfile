/*
Constructs the Docker tag to use for this build from the branch it was kicked off from. It is hardcoded to take the
"_latest" image from this branch as we always want to run the most recent version of this image in Jenkins. By
constructing it here, it allows the build to find the Docker image from the branch that is kicked off in Jenkins without
having to pass it in as a parameter to the build.
This is done as a function outside of the pipeline {} declaration as Jenkins cannot read custom environment variables
before the Kubernetes pod has started up.
*/
def getDockerTagFromBranch() {
    return "${env.BRANCH_NAME.replace("/","_").replace("-","_")}_latest"
}

/*
Constructs build summary messages intended to be posted in Slack
*/
def buildSlackMessage() {
    return """
branch:             ${env.BRANCH_NAME}
namespace:          ${params.NAMESPACE}
metadata:           ${params.METADATA}
psga_output_path:   ${params.PSGA_OUTPUT_PATH}
workdir:            ${params.NXF_WORK}
run:                ${params.ANALYSIS_RUN}
pathogen:           sars_cov_2
workflow:           ${params.NCOV_WORKFLOW}
filetype:           ${params.FILETYPE}
primer scheme:      ${params.PRIMER_SCHEME}
primer scheme_ver:  ${params.PRIMER_SCHEME_VERSION}
started by:         ${getTriggerDescription()}
"""
}

/*
Get the description of how a build was triggered.
*/
def getTriggerDescription() {
    def trigger = currentBuild.getBuildCauses()[0].shortDescription
    return trigger.contains('user') ? trigger.replace('Started by user ', '') : 'Automated trigger'
}

/*
The Slack channel that messages are sent to are dependent on the branch being built:
    - For dev builds, these are posted to a separate channel (to reduce the noise and make seeing results much clearer)
    - For all other builds, they are grouped together in a single channel to avoid polluting the dev channel
*/
def getSlackChannel() {
    return env.BRANCH_NAME == 'dev' ? '#psga-pipeline-ci-dev' : '#psga-pipeline-ci'
}


pipeline {

    parameters {
        booleanParam(name: 'VALIDATION_TEST', defaultValue: true, description: 'If true, run script for validating the results')
        string(name: 'METADATA', defaultValue: 's3://synthetic-data-dev/UKHSA/small_tests/illumina_fastq/metadata.csv', description: 'The path to the metadata CSV file containing the input file paths of the samples to process. This can be an S3 path')
        string(name: 'PSGA_OUTPUT_PATH', defaultValue: '/data/output/illumina_artic_fastq_short', description: 'The path to the output files. This can be an S3 path. In this latter case, please specify a path which does not yet exist, otherwise Nextflow will fail to store files due to a policy defined by Dev OPS in which pods are not allowed to delete/overwrite objects in S3.')
        string(name: 'NXF_WORK', defaultValue: '/data/work/illumina_artic_fastq_short', description: 'The path to Nextflow work directory. This can be an S3 path. In this latter case, please specify a path which does not yet exist, otherwise Nextflow will fail to store files due to a policy defined by Dev OPS in which pods are not allowed to delete/overwrite objects in S3.')
        string(name: 'ANALYSIS_RUN', defaultValue: 'illumina_artic_fastq_short', description: 'This can be the test name')
        choice(name: 'NCOV_WORKFLOW', choices: ['illumina_artic', 'medaka_artic', 'no_ncov'], description: 'The ncov workflow to run')
        choice(name: 'FILETYPE', choices: ['fastq', 'bam', 'fasta'], description: 'The input file type. illumina_artic supports fastq, bam; medaka_artic supports fastq; no_ncov supports fasta')
        string(name: 'PRIMER_SCHEME', defaultValue: 'nCoV-2019', description: 'The name of the primer scheme used by the ncov-artic pipeline')
        string(name: 'PRIMER_SCHEME_VERSION', defaultValue: 'V3', description: 'The version of the primer scheme used by the ncov-artic pipeline')

        string(name: 'CLUSTER_NAME', defaultValue: 'saas-dev.k8s.congenica.net', description: 'The Kubernetes cluster where the Congenica platform is deployed that the tests will run against.')
        string(name: 'NAMESPACE', defaultValue: 'psga', description: 'The Kubernetes namespace where the Congenica platform is deployed that the tests will run against.')

        string(name: 'PSGA_MAX_ATTEMPTS', defaultValue: '3', description: 'The maximum number of attempts resuming a failed pipeline')
        string(name: 'PSGA_SLEEP_TIME_BETWEEN_ATTEMPTS', defaultValue: '60', description: 'The sleep time between attempts')
        string(name: 'DOCKER_IMAGE_PREFIX', defaultValue: '144563655722.dkr.ecr.eu-west-1.amazonaws.com/congenica/dev', description: 'The docker image prefix to use')
        string(name: 'K8S_NODE', defaultValue: 'farmNode', description: 'The Kubernetes node to use as a nodeAffinity for worker jobs')
        string(name: 'K8S_PULL_POLICY', defaultValue: 'Always', description: 'The Kubernetes pull policy for docker images')
        string(name: 'K8S_STORAGE_MOUNT_PATH', defaultValue: '/data', description: 'The K8S storage mount path')
        string(name: 'K8S_QUEUE_SIZE', defaultValue: '5', description: 'The K8S job queue size')
        string(name: 'K8S_PROCESS_MAX_RETRIES', defaultValue: '3', description: 'The number of maximum retries for pipeline jobs')
        string(name: 'K8S_PROCESS_CPU_LOW', defaultValue: '1', description: 'The lowest number of cpus. The majority of jobs use this.')
        string(name: 'K8S_PROCESS_CPU_HIGH', defaultValue: '2', description: 'The highest number of cpus')
        string(name: 'K8S_PROCESS_MEMORY_VERY_LOW', defaultValue: '250', description: 'Memory setting')
        string(name: 'K8S_PROCESS_MEMORY_LOW', defaultValue: '500', description: 'Memory setting')
        string(name: 'K8S_PROCESS_MEMORY_MEDIUM', defaultValue: '1500', description: 'Memory setting')
        string(name: 'K8S_PROCESS_MEMORY_HIGH', defaultValue: '3000', description: 'Memory setting')
        string(name: 'K8S_PROCESS_MEMORY_VERY_HIGH', defaultValue: '6000', description: 'Memory setting')
        string(name: 'NXF_OPTS', defaultValue: '-Xms1g -Xmx4g', description: 'Nextflow options')

    }
    agent {
        kubernetes {
            cloud params.CLUSTER_NAME
            namespace params.NAMESPACE
            inheritFrom 'k8s-agent'
            serviceAccount "${params.NAMESPACE}-admin"
            yaml """
apiVersion: v1
kind: Pod
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: ${params.K8S_NODE}
            operator: In
            values:
            - "true"
  containers:
  - name: psga
    image: ${params.DOCKER_IMAGE_PREFIX}/psga-pipeline:${getDockerTagFromBranch()}
    imagePullPolicy: ${params.K8S_PULL_POLICY}
    command:
    - "sleep"
    args:
    - '1d'
    resources:
      limits:
        cpu: "2"
        memory: 6Gi
      requests:
        cpu: "2"
        memory: 6Gi
    volumeMounts:
    - mountPath: ${params.K8S_STORAGE_MOUNT_PATH}
      name: psga-persistent-storage
    - mountPath: "/home/jenkins/agent"
      name: "workspace-volume"
      readOnly: false
    workingDir: "/home/jenkins/agent"
  dnsPolicy: ClusterFirst
  restartPolicy: Never
  schedulerName: default-scheduler
  securityContext: {}
  volumes:
  - name: psga-persistent-storage
    persistentVolumeClaim:
      claimName: ${params.NAMESPACE}-pvc
  - emptyDir:
      medium: ""
    name: "workspace-volume"
"""
            defaultContainer 'psga'
        }
    }
    environment {
        PSGA_PIPELINE_DOCKER_IMAGE_TAG              = "${getDockerTagFromBranch()}"
        NCOV2019_ARTIC_NF_ILLUMINA_DOCKER_IMAGE_TAG = "${getDockerTagFromBranch()}"
        NCOV2019_ARTIC_NF_NANOPORE_DOCKER_IMAGE_TAG = "${getDockerTagFromBranch()}"
        PANGOLIN_DOCKER_IMAGE_TAG                   = "${getDockerTagFromBranch()}"
        PSGA_OUTPUT_PATH                            = "${params.PSGA_OUTPUT_PATH}"

        ANALYSIS_RUN                                = "${params.ANALYSIS_RUN}"
        METADATA                                    = "${params.METADATA}"
        NCOV_WORKFLOW                               = "${params.NCOV_WORKFLOW}"
        FILETYPE                                    = "${params.FILETYPE}"
        PRIMER_SCHEME                               = "${params.PRIMER_SCHEME}"
        PRIMER_SCHEME_VERSION                       = "${params.PRIMER_SCHEME_VERSION}"

        // other configs
        K8S_NODE                                    = "${params.K8S_NODE}"
        K8S_PULL_POLICY                             = "${params.K8S_PULL_POLICY}"
        PSGA_ROOT_PATH                              = "/app"
        PSGA_INCOMPLETE_ANALYSIS_RUNS_PATH          = "/data/incomplete_analysis_runs"
        PSGA_MAX_ATTEMPTS                           = "${params.PSGA_MAX_ATTEMPTS}"
        PSGA_SLEEP_TIME_BETWEEN_ATTEMPTS            = "${params.PSGA_SLEEP_TIME_BETWEEN_ATTEMPTS}"
        DOCKER_IMAGE_PREFIX                         = "${params.DOCKER_IMAGE_PREFIX}"
        K8S_QUEUE_SIZE                              = "${params.K8S_QUEUE_SIZE}"
        K8S_SERVICE_ACCOUNT                         = "${params.NAMESPACE}-admin"
        K8S_STORAGE_CLAIM_NAME                      = "${params.NAMESPACE}-pvc"
        K8S_STORAGE_MOUNT_PATH                      = "${params.K8S_STORAGE_MOUNT_PATH}"
        K8S_PROCESS_MAX_RETRIES                     = "${params.K8S_PROCESS_MAX_RETRIES}"
        K8S_PROCESS_CPU_LOW                         = "${params.K8S_PROCESS_CPU_LOW}"
        K8S_PROCESS_CPU_HIGH                        = "${params.K8S_PROCESS_CPU_HIGH}"
        K8S_PROCESS_MEMORY_VERY_LOW                 = "${params.K8S_PROCESS_MEMORY_VERY_LOW}"
        K8S_PROCESS_MEMORY_LOW                      = "${params.K8S_PROCESS_MEMORY_LOW}"
        K8S_PROCESS_MEMORY_MEDIUM                   = "${params.K8S_PROCESS_MEMORY_MEDIUM}"
        K8S_PROCESS_MEMORY_HIGH                     = "${params.K8S_PROCESS_MEMORY_HIGH}"
        K8S_PROCESS_MEMORY_VERY_HIGH                = "${params.K8S_PROCESS_MEMORY_VERY_HIGH}"
        NXF_WORK                                    = "${params.NXF_WORK}"
        NXF_ANSI_LOG                                = "false"
        NXF_EXECUTOR                                = "k8s"
        NXF_OPTS                                    = "${params.NXF_OPTS}"

        SLACK_CHANNEL                               = "${getSlackChannel()}"
    }
    stages {
        stage('Run PSGA pipeline') {
            steps {
                script {
                    // uncomment when testing
                    //sh 'printenv'

                    // cleanup
                    // NOTE: due to OPS policy, pods cannot delete objects in S3 buckets.
                    // fileExists() does not seem to work..
                    res = sh(script: "test -d ${PSGA_OUTPUT_PATH} && echo 'found' || echo 'not_found' ", returnStdout: true).trim()
                    if(res=='found'){
                        sh 'rm -rf ${PSGA_OUTPUT_PATH}'
                    }

                    // run the pipeline
                    // the argument `--load_missing_samples true` enables us to integration test the pipeline in isolation
                    sh 'nextflow -log ${ANALYSIS_RUN}.log run ${PSGA_ROOT_PATH}/psga/main.nf -c ${PSGA_ROOT_PATH}/psga/sars_cov_2.config --run ${ANALYSIS_RUN} --ncov_workflow ${NCOV_WORKFLOW} --filetype ${FILETYPE} --scheme ${PRIMER_SCHEME} --scheme_version ${PRIMER_SCHEME_VERSION} --metadata ${METADATA} -with-trace'

                    if (params.VALIDATION_TEST) {
                        // run validations
                        sh 'python ${PSGA_ROOT_PATH}/jenkins/validation.py --result-path ${PSGA_OUTPUT_PATH}/merged_output/pipeline_output.csv  --expected-result-path ${PSGA_ROOT_PATH}/tests/test_data/jenkins/expected_output/sars_cov_2/${ANALYSIS_RUN}/pipeline_output.csv sars_cov_2 --ncov-workflow ${NCOV_WORKFLOW}'
                    }

                    // copy main log, nxf work dir logs and reports to PSGA_OUTPUT_PATH
                    sh 'bash ${PSGA_ROOT_PATH}/psga/finalise.sh ${ANALYSIS_RUN}'

                }
            }
        }
    }
    post {
        success {
            script {
                if (params.VALIDATION_TEST) {
                    slackSend(
                        channel: "${env.SLACK_CHANNEL}",
                        color: 'good',
                        message: """
        :tick: <${env.BUILD_URL}|Jenkins Build #${env.BUILD_NUMBER}>
        ```${buildSlackMessage()}```
        """
                    )
                }
            }
        }
        failure {
            script {
                if (params.VALIDATION_TEST) {
                    slackSend(
                        channel: "${env.SLACK_CHANNEL}",
                        color: 'danger',
                        message: """
        :cross: <${env.BUILD_URL}|Jenkins Build #${env.BUILD_NUMBER}>
        ```${buildSlackMessage()}```
        """
                    )
                }
            }
        }
    }
}
